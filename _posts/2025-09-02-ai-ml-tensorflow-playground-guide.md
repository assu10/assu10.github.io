---
layout: post
title:  "AI - 텐서플로 플레이그라운드로 딥러닝 시작"
date: 2025-09-02
categories: dev
tags: ai ml tensorflow-playground deep-learning machine-learning neural-network 인공지능 딥러닝 머신러닝 신경망 텐서플로 feature-engineering hyperparameter overfitting
---

인공 신경망, 딥러닝 등 복잡한 이론들은 머릿속을 맴돌기만 하고, 명확한 개념이 잡히지 않아 답답할 수도 있다.  
직접 체험해보면 더 쉽게 이해할 수 있다.

여기서는 복잡한 이론 설명 대신, 구글에서 제공하는 딥러닝 놀이터인 [텐서플로 플레이그라운드(TensorFlow Playground)](https://playground.tensorflow.org)를 통해 직접 인공 신경망을 만져보고, 
눈으로 확인하며 그 원리를 이해해본다.

---

**목차**

<!-- TOC -->
* [1. 텐서플로 플레이그라운드](#1-텐서플로-플레이그라운드)
* [2. 출력 부분](#2-출력-부분)
* [3. 신경망의 구조 설계](#3-신경망의-구조-설계)
* [4. 데이터 입력 형태 선택](#4-데이터-입력-형태-선택)
* [참고 사이트 & 함께 보면 좋은 사이트](#참고-사이트--함께-보면-좋은-사이트)
<!-- TOC -->

---

# 1. 텐서플로 플레이그라운드

텐서플로 플레이그라운드는 코딩 없이 웹 브라우저에서 신경망 모델의 동작 원리를 시각적으로 탐색할 수 있는 도구이다.  

![Tensorflow Playground](/assets/img/dev/2025/0902/tensor.png)

화면의 기본 설정은 **분류(Classification)** 문제로, 주어진 데이터를 주황색과 파란색 두 그룹으로 정확하게 나누도록 신경망을 학습시키는 것이 목표이다.

화면을 살펴보면 레이어, 뉴런, 활성화 함수(Activation), 그리고 **뉴런들을 잇는 선**인 **[가중치(Weight)](https://assu10.github.io/dev/2025/08/31/ai-ml-neural-network-weights-and-activation-functions/#1-%EC%8B%A0%ED%98%B8%EB%A5%BC-%EC%A0%84%EB%8B%AC%ED%95%A0-%EB%95%8C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EA%B0%80%EC%A4%91%EC%B9%98weight%EC%99%80-%ED%8E%B8%ED%96%A5bias)** 등 인공 신경망의 핵심 구성 요소들이 시각적으로 표현되어 있다.  
여기서 파란색 데이터는 양수(+1), 주황색 데이터는 음수(-1) 값을 나타낸다.  
우리의 목표는 이 두 데이터를 완벽하게 구분하는 인공지능 모델을 만드는 것이다.

좌측 상단의 시작(▶) 버튼을 누르면 **에포크(Epoch)** 숫자가 빠르게 올라가는 것을 볼 수 있다.  
에포크는 전체 데이터를 사용해 신경망이 학습을 반복한 횟수를 의미하며, 이 숫자가 커질수록 모델의 학습이 진행되고 있음을 나타낸다.

---

먼저 상단에 있는 옵션들을 살펴보자.

- **Learning rate(학습률)**
  - 딥러닝 학습의 핵심 개념인 [경사 하강법](https://assu10.github.io/dev/2025/09/01/ai-ml-error-gradient-backpropagation/#21-%EA%B8%B0%EC%9A%B8%EA%B8%B0%EB%A1%9C-%EA%B0%80%EC%A4%91%EC%B9%98-%EA%B0%92%EC%9D%84-%EB%B3%80%EA%B2%BD%ED%95%98%EB%8A%94-%EA%B2%BD%EC%82%AC-%ED%95%98%EA%B0%95%EB%B2%95gradient-descent)과 관련한 값이다.
  - 정답과 예측값의 오차를 줄여나가는 과정에서 가중치를 얼마나 큰 폭으로 수정할지를 결정한다.
- **Activation([활성화 함수](https://assu10.github.io/dev/2025/08/31/ai-ml-neural-network-weights-and-activation-functions/#2-%EB%93%A4%EC%96%B4%EC%98%A4%EB%8A%94-%EC%8B%A0%ED%98%B8-%EC%84%B8%EA%B8%B0%EB%A5%BC-%EC%A1%B0%EC%A0%88%ED%95%98%EB%8A%94-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98-activation-function))**
  - 뉴런에 들어온 신호를 얼마나, 어떻게 다음 뉴런으로 전달할지 결정하는 함수이다.
  - 텐서플로 플레이그라운드에서는 렐루(ReLU), 하이퍼볼릭탄젠트(Tanh), 시그모이드(Sigmoid), 선형(Linear) 함수를 제공한다.
- **Regularization(정규화)**
  - 정규화의 목적은 과적합(overfitting)을 줄이는 것이다.
  - 모델이 학습 데이터에만 너무 치우쳐 학습되는 과적합을 방지하기 위한 기능이다.
  - 과적합된 모델은 학습 데이터는 100% 맞추지만, 새로운 데이터에 대해서는 예측 성능이 떨어지는 문제를 보인다.
- **Regularization rate**
  - 정규화를 얼마나 강하게 적용할지 결정하는 값이다.
- **Problem type([학습 방법](https://assu10.github.io/dev/2025/08/15/ai-ml-learning-methods-guide/#21-%EC%A7%80%EB%8F%84-%ED%95%99%EC%8A%B5supervised-learning-%EC%A0%95%EB%8B%B5%EC%9D%84-%EC%95%8C%EB%A0%A4%EC%A3%BC%EB%A9%B0-%EA%B0%80%EB%A5%B4%EC%B9%98%EA%B8%B0))**
  - 텐서플로 플레이그라운드에서는 문제를 **분류(Classification)**와 **회귀(Regression)**, 두 가지 유형의 문제를 풀어볼 수 있다.
  - 분류: 데이터를 주어진 카테고리(여기서는 주황색/파란색)로 나누는 문제
  - 회귀: 연속적인 숫자 값을 예측하는 문제(예: 키에 따른 몸무게 예측)

좌측에 있는 옵션들을 [4. 데이터 입력 형태 선택](#4-데이터-입력-형태-선택) 에 나옵니다.

---

# 2. 출력 부분

신경망 학습을 시작하면 에포크 수치가 증가하며, 출력 영역의 배경색과 그래프가 실시간으로 변화하는 것을 볼 수 있다.  
이는 모델이 데이터의 패턴을 학습하며 파란색과 주황색을 구분하는 경계선을 점차 찾아가는 과정이다.

![출력 화면](/assets/img/dev/2025/0902/output.png)

위 그림처럼 데이터 영역의 배경색이 각 데이터 그룹(파란색 점, 주황색 점)을 명확히 감싸고, 우측 상단의 손실 그래프(Loss graph)가 0에 가깝게 수렴했다면 
학습이 성공적으로 완료되었다는 신호이다. 이 때는 중단 버튼을 눌러 학습을 멈춰도 좋다.

텐서플로 플레이그라운드는 모델의 성능을 객관적으로 평가하기 위해 **훈련 데이터(training data)**와 **검증 데이터(test data)**로 나누어 사용한다.  
'Show test data' 체크박스를 클릭하면 학습에 사용되지 않은 검증 데이터를 표시해주어 눈으로 확인할 수 다.

이 두 데이터에 대한 모델의 성능은 각각 아래의 값으로 나타난다.
- **Test loss(검증 손실)**
  - 모델이 처음 보는 **검증 데이터에 대한 오차값**이다.
  - 이 값이 낮아야만 모델이 일반화된 예측 능력을 갖췄다고 말할 수 있다.
- **Training loss(훈련 손실)**
  - 모델이 학습에 사용한 **훈련 데이터에 대한 오차값**이다.
  - 이 값이 낮을수록 모델이 학습 내용을 잘 소화했다는 의미이다.

이상적인 학습은 두 손실 값이 함께 감소하여 낮은 수준으로 수렴하는 것이다.  
이 과정을 통해 모델이 단순히 정답을 외운 것이 아니라, 데이터에 내재된 진짜 패턴을 학습했는지 판단할 수 있다.

---

# 3. 신경망의 구조 설계

신경망의 성능은 그 구조에 크게 좌우된다.  
텐서플로 플레이그라운드에서는 **신경망의 깊이(레이어 수)**와 **너비(뉴런 수)**를 직접 조절하며 모델을 설계할 수 있다.

![신경망 설계](/assets/img/dev/2025/0902/structure.png)

---

**깊이: 은닉층(Hidden Layers)**

입력층과 출력층 사이에 여러 개의 **히든 레이어**를 추가하면, 신경망의 층이 깊어지며 이를 **심층 신경망(DNN, Deep Neural Network)**라고 한다.  
층이 깊어질수록 데이터의 더욱 복잡하고 추상적인 특징을 학습할 수 있어 정교한 모델을 만들 수 있다.  
하지만 그만큼 계산량이 늘어나 학습 시간이 길어지는 단점이 있다.

---

**너비: 뉴런(Neurons)**

각 레이어를 구성하는 **뉴런**의 개수 또한 조절할 수 있다.  
한 층의 뉴런 수가 많을수록 해당 레이어에서 더 다양한 특징을 잡아낼 수 있다.

하지만 무작정 층과 뉴런의 개수를 늘리는 것이 항상 좋은 결과를 보장하지는 않는다. 문제의 복잡도에 비해 과도하게 큰 신경망은 불필요한 계산을 수행하여 학습을 
비효율적으로 만들거나, 학습 데이터에만 과하게 적응하는 **과적합(Overfitting)**을 유발할 수 있다.

따라서 가장 효율적인 모델을 만들기 위해서는 주어진 상황에 맞는 적절한 레이어와 뉴런 개수를 찾아가는 과정이 중요하다.

---

# 4. 데이터 입력 형태 선택

훌륭한 인공지능 모델은 결국 '좋은 데이터'에서 시작한다.  
텐서플로 플레이그라운드에서는 다양한 형태의 데이터를 선택하고, 데이터의 특성을 조절하며 모델의 성능에 어떤 영향을 미치는지 직접 실험해볼 수 있다.

![데이터 입력 형태](/assets/img/dev/2025/0902/data.png)

화면 좌측 상단의 DATA 패널에서 학습에 사용할 데이터셋의 형태(원형, 나선형 등)을 선택하고, 아래 3가지 주요 파라미터를 조절할 수 있다.

- **Ratio of training to test data(훈련 데이터와 테스트 데이터의 비율)**
  - **의미**
    - 전체 데이터를 **학습용(training)**과 **평가용(혹은 검증용, test)**으로 나누는 비율
  - **설명**
    - 모델은 학습용 데이터를 보고 패턴을 익힌다. 학습이 끝난 뒤에는, 모델이 처음 보는 데이터인 평가용 데이터를 얼마나 잘 맞추는지 테스트하여 성능을 객관적으로 측정한다.
    - 30%로 설정되어 있다는 것은 전체 데이터의 30%를 학습에 사용하고 나머지 70%는 성능 평가에 사용한다는 의미이다.
  - **예시**
    - 학생이 **연습문제(학습 데이터)**로 공부한 뒤, 실력을 확인하기 위해 **실전 모의고사(테스트 데이터)**를 푸는 것
- **Noise**
  - **의미**
    - 데이터에 의도적으로 추가하는 **오류**
  - **설명**
    - Noise를 추가하면 데이터의 경계가 불분명해진다. 예를 들어 주황색 점들 사이에 파란색 점이 섞여들어가는 식이다.
    - 이는 모델이 데이터의 아주 세세한 부분까지 전부 외워버리는 **과적합(overfitting)**을 방지하고, 데이터의 전반적인 패턴을 학습하도록 유도하여 **모델의 예측력을 높이는데 도움**을 준다.
  - **예시**
    - 일부러 오타나 약간의 오류가 섞인 연습 문제를 풀게 해서, 핵심 개념을 더 확실히 이해하도록 만드는 훈련 방식
- **Batch size**
  - **의미**
    - 학습 데이터를 **한 번에 몇 개씩 묶어서** 모델에 넣고 학습시킬지 정하는 값
  - **설명**
    - 전체 학습 데이터를 한 번에 처리하면 컴퓨터에 부담이 크기 때문에, 보통 작은 묶음(batch)으로 나누어 학습을 진행한다.
    - 모델은 하나의 배치를 학습한 후, 결과를 반영하여 업데이트한다.
    - 배치 크기가 10이라는 것은 10개의 데이터 샘플을 한 묶음으로 하여 학습을 진행한다는 의미이다.
  - **예시**
    - 두꺼운 교과서 데이터를 한 번에 다 외우는 대신, **10페이지씩(배치 크기)** 나누어 읽고 복습하며 전체 내용을 점진적으로 학습해나가는 것

---

**FEATURES: 어떤 재료를 넣을 것인가**

단순히 원본 데이터(X1, X2)만 사용하는 것보다, 데이터의 분포 형태와 유사한 특징(Feature)을 추가로 입력하면 학습 효율과 성능을 극적으로 높일 수 있다.  
이를 특성 공학(Feature Engineering)이라고 한다.

![사분면](/assets/img/dev/2025/0902/output2.png)

예를 들어 위와 같이 사분면으로 데이터가 나뉜 경우, X 와 Y 의 부호가 중요하다.
- 제1사분면: X > 0, Y > 0
- 제2사분면: X < 0, Y > 0
- 제3사분면: X < 0, Y < 0
- 제4사분면: X > 0, Y < 0

FEATURES 에서 데이터 모습과 비슷한 입력을 선택하면 금방 학습이 진행되는 것을 확인할 수 있다.

만일 나선형처럼 복잡한 데이터를 학습시켜야 한다면 어떤 입력값을 넣어야 할까?  
이 때 X1, X2 외에 sin(X1), sin(X2) 와 같은 삼각함수 특성을 추가해주면, 모델이 나선형 패턴을 훨씬 빠르고 정확하게 학습할 수 있다는 것을 확인할 수 있다.

---

여기서 알 수 있는 것은 **'어떤 데이터를 어떻게 사용할 것인가'** 가 딥러닝 모델의 성패를 좌우한다는 점이다.  
단순히 데이터를 많이 넣고 오래 학습시킨다고 해서 좋은 모델이 만들어지는 것이 아니다.

문제의 본질을 파악하여 적절한 데이터를 선택 및 가공하고, 최적의 신경망 구조(레이어, 뉴런 수)를 설계하는 것이 인공지능 개발자의 중요한 역할이다.

---

# 참고 사이트 & 함께 보면 좋은 사이트

*본 포스트는 이영호 저자의 **모두의 인공지능 with 파이썬**을 기반으로 스터디하며 정리한 내용들입니다.*

* [모두의 인공지능 with 파이썬](https://product.kyobobook.co.kr/detail/S000217061005)
* [Tensorflow Playground](https://playground.tensorflow.org)